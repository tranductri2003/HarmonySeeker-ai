{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ESDjHx946Jr"
   },
   "source": [
    "## Installations and Imports :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1UdjUfD3j-7"
   },
   "outputs": [],
   "source": [
    "!pip install sklearn librosa tensorflow mir_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7167,
     "status": "ok",
     "timestamp": 1617147682074,
     "user": {
      "displayName": "Vojtech Lanz",
      "photoUrl": "",
      "userId": "15791523486540207166"
     },
     "user_tz": -120
    },
    "id": "5xfbSjrYxvCO"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "\n",
    "from numpy.lib.npyio import save\n",
    "from ACR_Training.Models import MLP, MLP_scalered, CRNN, CRNN_1, MLP2RNN, CRNN_2, BassVsThird\n",
    "from ACR_Training.Datasets import IsophonicsDataset\n",
    "from ACR_Training.SegmentationModels import SegmentationCRNN, EncoderDecoderSegmentation, colorize_spectrograms, chord_graphical_segmentations \n",
    "import sklearn\n",
    "import sys\n",
    "\n",
    "# Ignore warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4335,
     "status": "ok",
     "timestamp": 1617147682075,
     "user": {
      "displayName": "Vojtech Lanz",
      "photoUrl": "",
      "userId": "15791523486540207166"
     },
     "user_tz": -120
    },
    "id": "JuTSQ3fN5s0g"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "parser = argparse.ArgumentParser()\n",
    "# Directories, destinations, folders, files\n",
    "parser.add_argument(\"--isophonics_audio_directory\", default=\"./Datasets/Isophonics/AUDIO\", type=str, help=\"Path to ISOPHONICS directory with audio files.\")\n",
    "parser.add_argument(\"--isophonics_annotations_directory\", default=\"./Datasets/Isophonics/ANNOTATIONS\", type=str, help=\"Path to ISOPHONICS directory with chord annotations.\")\n",
    "parser.add_argument(\"--billboard_audio_directory\", default=\"./Datasets/Billboard/AUDIO\", type=str, help=\"Path to BILLBOARD directory with audio files.\")\n",
    "parser.add_argument(\"--billboard_annotations_directory\", default=\"./Datasets/Billboard/ANNOTATIONS\", type=str, help=\"Path to BILLBOARD directory with chord annotations.\")\n",
    "parser.add_argument(\"--isophonics_prep_dest\", default=\"./PreprocessedDatasets/isophonics_new.ds\", type=str, help=\"Preprocessed ISOPHONICS dataset destination.\")\n",
    "parser.add_argument(\"--billboard_prep_dest\", default=\"./PreprocessedDatasets/billboard_new.ds\", type=str, help=\"Preprocessed BILLBOARD dataset destination.\")\n",
    "\n",
    "# Dataset preprocessing args\n",
    "parser.add_argument(\"--dataset\", default=\"isophonics\", type=str, help=\"Dataset we want to preprocess, {isophonics, billboard}\")\n",
    "#           Isophonics\n",
    "parser.add_argument(\"--sample_rate\", default=44100, type=int, help=\"Sample rate for each song.\")\n",
    "parser.add_argument(\"--hop_length\", default=512, type=int, help=\"10*(sample_rate/hop_length) is a number of miliseconds between two frames.\")\n",
    "parser.add_argument(\"--window_size\", default=8, type=int, help=\"Spectrograms on left, and also spectrogram on right of the time bin -> window_size*2 + 1 spectrograms grouped together.\")\n",
    "parser.add_argument(\"--flattened_window\", default=False, type=bool, help=\"Whether the spectrogram window should be flatten to one array or it sould be array of spectrograms.\")\n",
    "parser.add_argument(\"--ms_intervals\", default=430.6640625, type=float, help=\"Miliseconds between generated spectrograms.\")\n",
    "parser.add_argument(\"--to_skip\", default=10, type=int, help=\"How many spectrogram we want to skip when creating spectrogram window.\")\n",
    "parser.add_argument(\"--norm_to_C\", default=True, type=bool, help=\"Whether we want to transpose all songs to C key (or D dorian, .. A minor, ...)\")\n",
    "parser.add_argument(\"--spectrogram_type\", default=\"cqt\", type=str, help=\"Spectrogram types, {cqt,log_mel}\")\n",
    "#           Billboard\n",
    "parser.add_argument(\"--n_frames\", default=1000, type=int, help=\"Length of song subsequence we are consinder when predicting chords to keep some context.\")\n",
    "\n",
    "# Training args\n",
    "parser.add_argument(\"--test_size\", default=0.3, type=lambda x:int(x) if x.isdigit() else float(x), help=\"Test set size.\")\n",
    "parser.add_argument(\"--epochs\", default=100, type=int, help=\"Number of epochs.\")\n",
    "parser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed.\")\n",
    "\n",
    "\n",
    "args = parser.parse_args([] if \"__file__\" not in globals() else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yizD2xg8i2o6"
   },
   "source": [
    "# DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 584,
     "status": "ok",
     "timestamp": 1617148059031,
     "user": {
      "displayName": "Vojtech Lanz",
      "photoUrl": "",
      "userId": "15791523486540207166"
     },
     "user_tz": -120
    },
    "id": "dFZkBI9Yi5iC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from ACR_Training.Models import MLP_scalered, CRNN_1\n",
    "from ACR_Training.Spectrograms import log_mel_spectrogram, cqt_spectrogram\n",
    "from ACR_Pipeline.KeyRecognizer import KeyRecognizer\n",
    "from ACR_Pipeline.DataPreprocessor import DataPreprocessor\n",
    "from ACR_Pipeline.ChordVoter import ChordVoter\n",
    "\n",
    "def pipeline(waveform, sample_rate, hop_length, n_frames, spectrogram_type):\n",
    "     # Load models\n",
    "    basic_crnn = CRNN()\n",
    "    basic_crnn.load('./ACR_Pipeline/models/original_crnn.h5')\n",
    "    C_transposed_crnn = CRNN()\n",
    "    C_transposed_crnn.load('./ACR_Pipeline/models/transposed_crnn.h5')\n",
    "\n",
    "\n",
    "\n",
    "    # Preprocess Data\n",
    "    x = DataPreprocessor.sequence_preprocess(\n",
    "        waveform=waveform,\n",
    "        sample_rate=sample_rate,\n",
    "        hop_length=hop_length,\n",
    "        n_frames=n_frames,\n",
    "        spectrogram_generator=spectrogram_type,\n",
    "        norm_to_C=False,\n",
    "    )\n",
    "\n",
    "    # Get list of played chords\n",
    "    \"\"\" MLP Part, not that accurate\n",
    "    baisc_chord_prediction = basic_crnn.predict(x)\n",
    "    \"\"\"\n",
    "    baisc_chord_prediction = basic_crnn.predict(x).argmax(axis=2).flatten()\n",
    "    chords, counts = np.unique(baisc_chord_prediction, return_counts=True)\n",
    "    chord_counts = dict(zip(chords, counts))\n",
    "\n",
    "    # Get song's key (not really tonic, A minor/ailoian is same as a C major or D dorian)\n",
    "    key = KeyRecognizer.estimate_key(chord_counts)\n",
    "\n",
    "    # Tranapose Song to a C major\n",
    "    x_transposed = DataPreprocessor.sequence_preprocess(\n",
    "        waveform=waveform,\n",
    "        sample_rate=sample_rate,\n",
    "        hop_length=hop_length,\n",
    "        n_frames=n_frames,\n",
    "        spectrogram_generator=spectrogram_type,\n",
    "        norm_to_C=True,\n",
    "        key=key,\n",
    "    )\n",
    "\n",
    "    # Get chord sequence of a song\n",
    "    transposed_chord_prediction = C_transposed_crnn.predict(x_transposed).argmax(axis=2).flatten()\n",
    "\n",
    "\n",
    "    # Chord voting for each beat\n",
    "    chord_sequence, bpm = ChordVoter.vote_for_beats(\n",
    "        chord_sequence=transposed_chord_prediction,\n",
    "        waveform=waveform, sample_rate=sample_rate,\n",
    "        hop_length=hop_length\n",
    "    )\n",
    "\n",
    "    # Transpose to the original sequence\n",
    "    original_chord_sequence = DataPreprocessor.transpose(\n",
    "        chord_sequence=chord_sequence,\n",
    "        from_key = 'C',\n",
    "        to_key = key\n",
    "    )\n",
    "\n",
    "    return DataPreprocessor.chord_indices_to_notations(original_chord_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36130,
     "status": "ok",
     "timestamp": 1617148282234,
     "user": {
      "displayName": "Vojtech Lanz",
      "photoUrl": "",
      "userId": "15791523486540207166"
     },
     "user_tz": -120
    },
    "id": "gDIsM3Y4l7LR",
    "outputId": "3c7f6461-e1d2-4767-acaa-13d0de69f4dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'F', 'F', 'D#', 'D#', 'D#', 'D#', 'G', 'G', 'C', 'C', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'C', 'C', 'C', 'C', 'C', 'C', 'D', 'D', 'G', 'G', 'G', 'G', 'G', 'G', 'G', 'G', 'N', 'N', 'G', 'G', 'A:min', 'A:min', 'A:min', 'A:min', 'N', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'D', 'D', 'D', 'D', 'F', 'F', 'F', 'F', 'D#', 'D#', 'D#', 'D#', 'G', 'G', 'C', 'C', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'C', 'C', 'C', 'C', 'C', 'C', 'D', 'D', 'G', 'G', 'G', 'G', 'G', 'G', 'G', 'G', 'N', 'N', 'G', 'A:min', 'A:min', 'A:min', 'A:min', 'A:min', 'N', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'D', 'D', 'D', 'D', 'F', 'F', 'F', 'F', 'D#', 'D#', 'D#', 'D#', 'G', 'G', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C#:min', 'C#:min', 'C#:min', 'C#:min', 'F#:min', 'F#:min', 'F#:min', 'F#:min', 'A', 'A', 'A', 'D', 'D', 'D', 'D', 'D', 'G', 'G', 'G', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C#:min', 'C#:min', 'C#:min', 'C#:min', 'F#:min', 'F#:min', 'F#:min', 'F#:min', 'A', 'A', 'A', 'D', 'D', 'D', 'D', 'D', 'G', 'G', 'G', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'C', 'C', 'C', 'C', 'C', 'D', 'D', 'D', 'G', 'G', 'G', 'G', 'G', 'G', 'G', 'N', 'N', 'N', 'G', 'A:min', 'A:min', 'A:min', 'A:min', 'N', 'N', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'D', 'D', 'D', 'D', 'F', 'F', 'F', 'D#', 'D#', 'D#', 'D#', 'D#', 'G', 'G', 'C', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'E:min', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'C', 'C', 'C', 'C', 'C', 'C', 'D', 'D', 'G', 'G', 'G', 'G', 'G', 'G', 'G', 'G', 'N', 'N', 'G', 'G', 'A:min', 'A:min', 'A:min', 'A:min', 'N', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'D', 'D', 'D', 'D', 'F', 'F', 'F', 'F', 'D#', 'D#', 'D#', 'D#', 'G', 'G', 'A', 'A', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'D#', 'D#', 'D#', 'D#', 'N']\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "from ACR_Training.Spectrograms import cqt_spectrogram\n",
    "# Load audio\n",
    "y, sr = librosa.load('Something.wav', 22050)\n",
    "\n",
    "# Predict chords\n",
    "sequence = pipeline(\n",
    "    waveform=y,\n",
    "    sample_rate=sr,\n",
    "    hop_length=512,\n",
    "    n_frames=1000,\n",
    "    spectrogram_type=cqt_spectrogram,\n",
    ")\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18894,
     "status": "ok",
     "timestamp": 1617148095434,
     "user": {
      "displayName": "Vojtech Lanz",
      "photoUrl": "",
      "userId": "15791523486540207166"
     },
     "user_tz": -120
    },
    "id": "nxy6sDj-iFkN",
    "outputId": "4d2add2c-33be-4205-9f23-23c551d2c7a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G', 'G', 'G', 'A:min', 'A:min', 'A:min', 'F', 'F', 'F', 'F', 'F', 'C', 'C', 'C', 'C', 'G', 'G', 'G', 'G', 'F', 'F', 'F', 'F', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'G', 'G', 'G', 'G', 'G', 'G', 'A:min', 'A:min', 'A:min', 'F', 'F', 'F', 'F', 'F', 'A#', 'C', 'C', 'G', 'G', 'G', 'G', 'F', 'F', 'F', 'C', 'C', 'C', 'C', 'C', 'C', 'G', 'G', 'G', 'G', 'G', 'G', 'G', 'G', 'A:min', 'A:min', 'A:min', 'C', 'F', 'C', 'C', 'C', 'C', 'C', 'C', 'G', 'G', 'G', 'F', 'F', 'F', 'F', 'F', 'C', 'C', 'C', 'C', 'A:min', 'A:min', 'A:min', 'A:min', 'G', 'G', 'G', 'G', 'F', 'F', 'F', 'F', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'G', 'G', 'G', 'G', 'F', 'F', 'F', 'F', 'C', 'C', 'C', 'C', 'N', 'N', 'N']\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "from ACR_Training.Spectrograms import cqt_spectrogram\n",
    "# Load audio\n",
    "#y, sr = librosa.load('Help!.wav', 44100)\n",
    "y, sr = librosa.load('Let it be 120bpm.wav', 22050)\n",
    "\n",
    "# Predict chords\n",
    "sequence = pipeline(\n",
    "    waveform=y,\n",
    "    sample_rate=sr,\n",
    "    hop_length=512,\n",
    "    n_frames=1000,\n",
    "    spectrogram_type=cqt_spectrogram,\n",
    ")\n",
    "print(sequence)\n",
    "[\n",
    "    {\n",
    "        \"chord\": \"C\",\n",
    "        \"start_time\": 0,\n",
    "        \"end_time\": 1.0\n",
    "    },\n",
    "    {\n",
    "        \"chord\": \"D\",\n",
    "        \"start_time\": 1.0,\n",
    "        \"end_time\": 2.0\n",
    "    },\n",
    "    {\n",
    "        \"chord\": \"E\",\n",
    "        \"start_time\": 2.0,\n",
    "        \"end_time\": 3.0\n",
    "    },\n",
    "    {\n",
    "        \"chord\": \"N\",\n",
    "        \"start_time\": 3.0,\n",
    "        \"end_time\": 4.0\n",
    "    },\n",
    "    {\n",
    "        \"chord\": \"G\",\n",
    "        \"start_time\": 4.0,\n",
    "        \"end_time\": 5.0\n",
    "    },\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOXvM7Ige7hntWrT9sZizc5",
   "collapsed_sections": [
    "2ESDjHx946Jr"
   ],
   "name": "Bachelor Research - Demo.ipynb",
   "provenance": [
    {
     "file_id": "1q0CBZvkEVnTFQFsuf7CEEwASvrA_aOnn",
     "timestamp": 1616363879529
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
